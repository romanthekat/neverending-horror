{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse raw posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'twosentencehorror.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_json(raw_filename):\n",
    "    with open(raw_filename) as f:\n",
    "        posts_json = json.load(f)\n",
    "\n",
    "    posts_raw = []\n",
    "    for post in posts_json['data']:\n",
    "        if \"title\" in post and \"selftext\" in post:\n",
    "            posts_raw.append(post['title'] + '. ' + post['selftext'])\n",
    "\n",
    "    return posts_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_output(posts, filename):\n",
    "    with open(filename, 'a') as f:\n",
    "        for post in posts:\n",
    "            f.write(post + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_output(parse_raw_json('twosentencehorror_raw_top.json'), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_output(parse_raw_json('twosentencehorror_raw_58.json'), output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file) as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = markovify.Text(text, state_size=4)\n",
    "\n",
    "generated = 0\n",
    "required = 42\n",
    "while True:\n",
    "    sentence = text_model.make_sentence()\n",
    "    if sentence:\n",
    "        generated+=1\n",
    "        print(sentence)\n",
    "    \n",
    "    if generated == required:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was a Great friend's friend to have a comp because of date starts discover the same top of the state out of the same turns of way here and have to find those in the police character on the world is down. I did as a girl who was the worst time I can submit the start to the surviving game to help m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen = textgenrnn()\n",
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,209 texts collected.\n",
      "Training on 1,593,420 character sequences.\n",
      "Epoch 1/2\n",
      " 7526/12448 [=================>............] - ETA: 9:00 - loss: 1.3280"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file(output_file, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textgen.generate(42))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
